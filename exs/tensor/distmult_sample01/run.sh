#!/bin/sh
cd `dirname $0`

mkdir -p distmult_sample_tmp

##
## Construction of explanation graph
##
upprism distmult_sample.psm 

##
## Training
## input: the generated intermediate files generated by the above command
## Minibatch SGD trainging is done by minimizing the loss function (preference_pair: preference-pair loss function for rank learning)
## The optional arguments determine training parameters: the number of epoch (--max_iterate) and the learning rate in the training phase.
##
tprism train \
    --input ./distmult_sample_tmp/ \
    --sgd_loss preference_pair     \
    --max_iterate 10            \
    --sgd_learning_rate 0.01 --cpu

